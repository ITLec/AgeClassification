{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WC7GamCEBEjM",
        "outputId": "8ba12493-a857-4378-c620-d7dfed2c0cae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0o_ZLvss-Jy",
        "outputId": "b7712e8f-4122-44e3-d4c4-39e4e3ce4eac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 553 images belonging to 2 classes.\n",
            "Found 138 images belonging to 2 classes.\n",
            "Found 120 images belonging to 2 classes.\n",
            "Epoch 1/100\n",
            "9/9 [==============================] - 130s 14s/step - loss: 0.7256 - accuracy: 0.5588 - val_loss: 0.6610 - val_accuracy: 0.6159\n",
            "Epoch 2/100\n",
            "9/9 [==============================] - 99s 11s/step - loss: 0.5399 - accuracy: 0.7197 - val_loss: 0.5544 - val_accuracy: 0.7101\n",
            "Epoch 3/100\n",
            "9/9 [==============================] - 105s 12s/step - loss: 0.4784 - accuracy: 0.7776 - val_loss: 0.5010 - val_accuracy: 0.7464\n",
            "Epoch 4/100\n",
            "9/9 [==============================] - 121s 14s/step - loss: 0.4165 - accuracy: 0.8174 - val_loss: 0.4572 - val_accuracy: 0.7899\n",
            "Epoch 5/100\n",
            "9/9 [==============================] - 100s 12s/step - loss: 0.3939 - accuracy: 0.8300 - val_loss: 0.4483 - val_accuracy: 0.8333\n",
            "Epoch 6/100\n",
            "9/9 [==============================] - 101s 11s/step - loss: 0.3779 - accuracy: 0.8391 - val_loss: 0.4362 - val_accuracy: 0.7899\n",
            "Epoch 7/100\n",
            "9/9 [==============================] - 101s 11s/step - loss: 0.3578 - accuracy: 0.8590 - val_loss: 0.4130 - val_accuracy: 0.8333\n",
            "Epoch 8/100\n",
            "9/9 [==============================] - 111s 13s/step - loss: 0.3384 - accuracy: 0.8698 - val_loss: 0.3998 - val_accuracy: 0.8261\n",
            "Epoch 9/100\n",
            "9/9 [==============================] - 101s 11s/step - loss: 0.3298 - accuracy: 0.8662 - val_loss: 0.3976 - val_accuracy: 0.8478\n",
            "Epoch 10/100\n",
            "9/9 [==============================] - 102s 11s/step - loss: 0.3284 - accuracy: 0.8734 - val_loss: 0.3939 - val_accuracy: 0.8188\n",
            "Epoch 11/100\n",
            "9/9 [==============================] - 102s 12s/step - loss: 0.3019 - accuracy: 0.8933 - val_loss: 0.3981 - val_accuracy: 0.8261\n",
            "Epoch 12/100\n",
            "9/9 [==============================] - 101s 12s/step - loss: 0.2911 - accuracy: 0.8861 - val_loss: 0.3992 - val_accuracy: 0.8261\n",
            "Epoch 13/100\n",
            "9/9 [==============================] - 102s 11s/step - loss: 0.2685 - accuracy: 0.8951 - val_loss: 0.3853 - val_accuracy: 0.8478\n",
            "Epoch 14/100\n",
            "9/9 [==============================] - 101s 11s/step - loss: 0.2745 - accuracy: 0.8987 - val_loss: 0.3868 - val_accuracy: 0.8406\n",
            "2/2 - 21s - loss: 0.4954 - accuracy: 0.8000 - 21s/epoch - 11s/step\n",
            "Test accuracy: 0.800000011920929\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define the input image size and batch size\n",
        "img_width, img_height = 224, 224\n",
        "batch_size = 64\n",
        "\n",
        "# Define the directory for the training data\n",
        "train_data_dir = '/content/drive/MyDrive/AgeClassification/train/'\n",
        "\n",
        "# Define the directories for the test data\n",
        "test_data_dir = '/content/drive/MyDrive/AgeClassification/test/'\n",
        "\n",
        "# Create an ImageDataGenerator for the training and validation sets with data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2,  # Use 20% of the training data for validation\n",
        ")\n",
        "\n",
        "# Create an ImageDataGenerator for the test set\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "# Load the training and validation images from the directory\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    classes=['children', 'adults'],\n",
        "    shuffle=True,\n",
        "    subset='training',  # Use the subset of the data for training\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    classes=['children', 'adults'],\n",
        "    shuffle=False,\n",
        "    subset='validation',  # Use the subset of the data for validation\n",
        ")\n",
        "\n",
        "# Load the test images from the directory\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    classes=['children', 'adults'],\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "# Load the pre-trained ResNet50 model and remove the top layer\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "\n",
        "# Add a global average pooling layer and a dense output layer with sigmoid activation\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Define the full model by combining the base model and the added layers\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Freeze the layers of the pre-trained ResNet50 model to prevent retraining\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model with binary crossentropy loss and Adam optimizer\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the training data and validate on the validation data\n",
        "model.fit(train_generator, epochs=100,\n",
        "          validation_data=val_generator,\n",
        "          callbacks= [tf.keras.callbacks.EarlyStopping(\n",
        "              patience=5, #\n",
        "              monitor='val_accuracy',\n",
        "              restore_best_weights=True\n",
        "          )])\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(test_generator, verbose=2)\n",
        "\n",
        "# Print the test accuracy\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3criqBaxVvn"
      },
      "source": [
        "#Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRWuDMusz9tw"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/AgeClassification/modelAgeClassificationV3_Full.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLsXXmjO3cc8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}